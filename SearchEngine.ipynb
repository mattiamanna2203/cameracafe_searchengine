{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2111047f-d00a-4cbf-85dc-f3bc958de0ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Importazione"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a7c584-cb45-4860-867a-56b3f74ce7cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importazione pacchetti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf98f9f-0921-43a4-a61b-233ca226a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "#from  tqdm import tqdm\n",
    "import math\n",
    "from IPython.display import display, HTML\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from nltk.stem import SnowballStemmer\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ac5999-6250-4993-a619-566bc1c34e5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf7a86d3-e037-47ee-b796-ed638078dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Dati/dati_puliti.csv\")\n",
    "df.drop(columns={'Unnamed: 0'},inplace=True)\n",
    "\n",
    "DF2=pd.read_csv(\"Dati/tfidf_index.csv\", index_col=None)\n",
    "DF2.drop(columns={'Unnamed: 0'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e8560-013b-420b-85b4-6c1c55efba0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e3bb5e-8c47-4f32-b697-ce1c21f5485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Dati/vocabulary.json\", 'r') as v:\n",
    "    vocabulary = json.load(v)\n",
    "    \n",
    "with open(\"Dati/vocabulary.json\", 'r') as wd:\n",
    "    word_dict  = json.load(wd)\n",
    "    \n",
    "with open(\"Dati/inverted_idx.json\", 'r') as inv_idx:\n",
    "    inverted_idx = json.load(inv_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a5a3af-d522-4991-a828-a1d72c4d0298",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5e264b-75a0-4e7e-ab94-25141c27180e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f88baa-1e83-4479-a8f9-a292bc7797cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text(txt):\n",
    "    stemmer_snowball = SnowballStemmer('italian')\n",
    "    doc = nlp(txt.lower())\n",
    "    return [re.sub(\"[\\\"”“/}/(/)/{!?\\]\\[#@]*\\\\n\",\"\",stemmer_snowball.stem(token.lemma_)) for token in doc if not token.is_punct and token.pos_ not in ['DET', 'CCONJ']]\n",
    "\n",
    "df['list_words'] =df.title_trama.apply(lambda row: stem_text(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90226d41-d39a-472a-9b71-3a728c8ff117",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Ranking engine all Match\n",
    "Un documento deve contenere tutte le parole presenti nella query per essere ritrovato"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983e5b31-6f5f-465c-b3b4-290ca24fc15a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7ca3f69-7e03-4ffc-85d3-7c7a8b389e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def querty_td_idf_allMatch(query_str):\n",
    "    #Inizialize dataset\n",
    "    td_inf={}\n",
    "    \n",
    "    #Remove double spaces\n",
    "    query_str=re.sub(\"\\s{2,}\",\" \",query_str)\n",
    "    \n",
    "    #Stem the query\n",
    "    stemmed_query=stem_text(query_str)\n",
    "    \n",
    "    \n",
    "    word_in_query=set(stemmed_query)\n",
    "    \n",
    "    \n",
    "    for word in word_in_query:\n",
    "    \n",
    "        \n",
    "        #DF document frequency\n",
    "        df_t=vocabulary[word]\n",
    "        if df_t==0:\n",
    "            raise Exception(\"Can't find a document that contain all the word in the query, check input for misspelled words.\")\n",
    "           # raise Value Error(\"Can't find a document that contain all the word in the query, check input for misspelled words.\")\n",
    "            #print(\"Can't find a document that contain all the word in the query, check input for misspelled words.\")\n",
    "            #return None\n",
    "        else:\n",
    "    \n",
    "            #TF\n",
    "            ##occurence of t word in the query\n",
    "            t_in_document=\" \".join(stemmed_query).count(word) #count on total query or stemmed query? for now stemmed query\n",
    "\n",
    "\n",
    "            ##Word in  the query\n",
    "            parole_in_d=len(stemmed_query) #count on stemmed query or total query?for now stemmed query\n",
    "\n",
    "            tf=t_in_document/parole_in_d\n",
    "            \n",
    "            #DF document frequency\n",
    "            #df_t=vocabulary[word]\n",
    "            results = [inverted_idx[str(item)] for item in [word_dict[word] for word in stemmed_query if word in vocabulary]]\n",
    "            df_t=len(results)\n",
    "\n",
    "            #Inverse document frequency\n",
    "            #N=len(df)\n",
    "            N=7200\n",
    "            idf=math.log(N/(df_t+1))\n",
    "\n",
    "\n",
    "            #TD-INF\n",
    "            td_inf_i=tf* idf\n",
    "\n",
    "            td_inf[word]=td_inf_i  #dictionary of td_idf for every word in the query\n",
    "\n",
    "    dataset=pd.DataFrame([td_inf])\n",
    "    return dataset\n",
    "\n",
    "def query_ranking_allMatch(query_str,k,season=None):\n",
    "    t=\"\"\n",
    "    for i in set(query_str.split()):\n",
    "        t += i + \" \"\n",
    "    query_str=t.strip()\n",
    "\n",
    "    query_str=re.sub(\"\\s{2,}\",\" \",query_str)\n",
    "    \n",
    "    parole=[word for word in stem_text(query_str)]\n",
    "    check_parole=[word for word in stem_text(query_str) if word in vocabulary]\n",
    "    if len(parole)== len(check_parole):\n",
    "        \n",
    "\n",
    "        indici=list(DF2[stem_text(query_str)][(DF2[stem_text(query_str)].T != 0).all()].index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #Inizialize a list for store the value of cosine_similarity\n",
    "        list_cosine_similarity=[]\n",
    "\n",
    "        #Define a new dataset. In this dataset we will add the cosine similarity.\n",
    "        data=df[df.index.isin(indici)][['season', 'episodio', 'titolo', 'trama', 'guest_star', 'prima_visione']]\n",
    "\n",
    "\n",
    "        #Define a new dataset. In this dataset we will put the tf-idf of the matching documents.\n",
    "        a=DF2[DF2.index.isin(indici)][stem_text(query_str)]\n",
    "        a=a.reindex(sorted(a.columns), axis=1) \n",
    "\n",
    "        #Evaluate tf-idf of query\n",
    "        td_idf_query=querty_td_idf_allMatch(query_str)\n",
    "        td_idf_query=td_idf_query.reindex(sorted(a.columns), axis=1) \n",
    "\n",
    "\n",
    "\n",
    "        #Evaluate cosine similarity between each document and the query.\n",
    "\n",
    "\n",
    "        for i,row in a.iterrows():\n",
    "\n",
    "\n",
    "            num=np.dot(td_idf_query.values.flatten(),row.values)\n",
    "            den=np.linalg.norm(td_idf_query.values.flatten()) * np.linalg.norm(row.values)\n",
    "\n",
    "            cosine=num/den\n",
    "            list_cosine_similarity.append(cosine)\n",
    "\n",
    "        data[\"Similarity\"]= list_cosine_similarity\n",
    "        dd=data.sort_values(\"Similarity\",ascending=False)\n",
    "        if season==None:\n",
    "            dd=dd[['season', 'episodio', 'titolo', 'trama', 'guest_star', 'prima_visione']]\n",
    "        else:\n",
    "            dd=dd[['season', 'episodio', 'titolo', 'trama', 'guest_star', 'prima_visione']][df.season==season]\n",
    "        dd.reset_index(drop=True,inplace=True)\n",
    "        display(HTML(dd.head(k).to_html()))\n",
    "        \n",
    "        #return dd\n",
    "\n",
    "    else:\n",
    "        print(\"Impossibile trovare un documento che contenga tutta la parola nella query, controllare l'input per le parole errate.\")\n",
    "       # return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b51b0f4-eb87-47b6-8b87-f3b1f45dffc9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Ranking engine\n",
    "Vengono ritornati i primi k documenti più rilevanti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4400bf-7b4a-4b25-ac8f-4ebdf0f1b575",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6aa5f6dd-ecb6-433b-85a3-c76deeb827a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def querty_td_idf(query_str):\n",
    "    #Inizialize dataset\n",
    "    td_inf={}\n",
    "    \n",
    "    #Remove double spaces\n",
    "    query_str=re.sub(\"\\s{2,}\",\" \",query_str)\n",
    "    \n",
    "    #Stem the query\n",
    "    stemmed_query=stem_text(query_str)\n",
    "    \n",
    "    \n",
    "    word_in_query=set(stemmed_query)\n",
    "    \n",
    "    \n",
    "    for word in word_in_query:\n",
    "        #DF document frequency\n",
    "        df_t=vocabulary[word]\n",
    "        if df_t==0:\n",
    "            raise Exception(\"Can't find a document that contain all the word in the query, check input for misspelled words.\")\n",
    "           # raise Value Error(\"Can't find a document that contain all the word in the query, check input for misspelled words.\")\n",
    "            #print(\"Can't find a document that contain all the word in the query, check input for misspelled words.\")\n",
    "            #return None\n",
    "        else:\n",
    "    \n",
    "            #TF\n",
    "            ##occurence of t word in the query\n",
    "            t_in_document=\" \".join(stemmed_query).count(word) #count on total query or stemmed query? for now stemmed query\n",
    "\n",
    "\n",
    "            ##Word in  the query\n",
    "            parole_in_d=len(stemmed_query) #count on stemmed query or total query?for now stemmed query\n",
    "\n",
    "            tf=t_in_document/parole_in_d\n",
    "            \n",
    "            #DF document frequency\n",
    "            #df_t=vocabulary[word]\n",
    "            results = [inverted_idx[str(item)] for item in [word_dict[word] for word in stemmed_query if word in vocabulary]]\n",
    "            df_t=len(results)\n",
    "\n",
    "            #Inverse document frequency\n",
    "            #N=len(df)\n",
    "            N=7200\n",
    "            idf=math.log(N/(df_t+1))\n",
    "\n",
    "\n",
    "            #TD-INF\n",
    "            td_inf_i=tf* idf\n",
    "\n",
    "            td_inf[word]=td_inf_i  #dictionary of td_idf for every word in the query\n",
    "\n",
    "    dataset=pd.DataFrame([td_inf])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a2a2a73-5e1d-4bdc-bb96-716c8f7679d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_ranking(query_str,k,season=None):\n",
    "    t=\"\"\n",
    "    for i in set(query_str.split()):\n",
    "        t += i + \" \"\n",
    "    query_str=t.strip()\n",
    "\n",
    "    query_str=re.sub(\"\\s{2,}\",\" \",query_str)\n",
    "\n",
    "    parole=[word for word in stem_text(query_str)]\n",
    "    check_parole=[word for word in stem_text(query_str) if word in vocabulary]\n",
    "\n",
    "\n",
    "    indici=list(DF2[stem_text(query_str)].index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Inizialize a list for store the value of cosine_similarity\n",
    "    list_cosine_similarity=[]\n",
    "\n",
    "\n",
    "\n",
    "    #Define a new dataset. In this dataset we will add the cosine similarity.\n",
    "    data=df[df.index.isin(indici)][['season', 'episodio', 'titolo', 'trama', 'guest_star', 'prima_visione']]\n",
    "\n",
    "\n",
    "    #Define a new dataset. In this dataset we will put the tf-idf of the matching documents.\n",
    "    a=DF2[DF2.index.isin(indici)][stem_text(query_str)]\n",
    "    a=a.reindex(sorted(a.columns), axis=1) \n",
    "\n",
    "    #Evaluate tf-idf of query\n",
    "    td_idf_query=querty_td_idf(query_str)\n",
    "    td_idf_query=td_idf_query.reindex(sorted(a.columns), axis=1) \n",
    "\n",
    "\n",
    "    #Evaluate cosine similarity between each document and the query.\n",
    "\n",
    "\n",
    "    for i,row in a.iterrows():\n",
    "\n",
    "        num=np.dot(td_idf_query.values.flatten(),row.values)\n",
    "        den=np.linalg.norm(td_idf_query.values.flatten()) * np.linalg.norm(row.values)\n",
    "\n",
    "        cosine=num/den\n",
    "        list_cosine_similarity.append(cosine)\n",
    "\n",
    "    data[\"Similarity\"]= list_cosine_similarity\n",
    "    dd=data.sort_values(\"Similarity\",ascending=False)\n",
    "    #dd=dd[['season', 'episodio', 'titolo', 'trama', 'guest_star', 'prima_visione','Similarity']]\n",
    "    if season==None:\n",
    "        dd=dd[['season', 'episodio', 'titolo', 'trama', 'guest_star', 'prima_visione']]\n",
    "    else:\n",
    "        dd=dd[['season', 'episodio', 'titolo', 'trama', 'guest_star', 'prima_visione']][df.season==season]\n",
    "    dd.reset_index(drop=True,inplace=True)\n",
    "    display(HTML(dd.head(k).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3f5c05-079a-42ff-a638-358fe1da614b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Try the ranking engine all Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c83cf2ad-831e-4538-88d6-71f74be48ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episodio</th>\n",
       "      <th>titolo</th>\n",
       "      <th>trama</th>\n",
       "      <th>guest_star</th>\n",
       "      <th>prima_visione</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>Girano voci</td>\n",
       "      <td>Le addette alle pulizie rivelano a Luca e Paolo che, secondo alcune voci, saranno trasferiti in Cina.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22 settembre 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>355</td>\n",
       "      <td>Regressione</td>\n",
       "      <td>Luca prende una brutta botta in testa e regredisce fino all'età di 6 anni. Paolo è costretto a prendersene cura.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18 febbraio 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>La moneta</td>\n",
       "      <td>Luca e Paolo vogliono prendersi un caffè, ma sono senza monete.</td>\n",
       "      <td>['Bedy Moratti']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>417</td>\n",
       "      <td>La scommessa</td>\n",
       "      <td>Luca e Paolo costringono Silvano a fare delle scommesse stupide con loro.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18 aprile 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>143</td>\n",
       "      <td>La vedova</td>\n",
       "      <td>Luca e Paolo vogliono convincere la vedova di un dirigente defunto a lasciare loro parte dell'eredità.</td>\n",
       "      <td>['Anna Bonasso']</td>\n",
       "      <td>1º febbraio 2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k=5\n",
    "query=\"luca paolo\"\n",
    "query_ranking_allMatch(query,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e815cc-f2ba-4511-8d38-f69609362860",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Try the ranking engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00c3b015-4384-47a5-8c19-763491273918",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j4/9fk3st2d30g22vff83pj6cnw0000gn/T/ipykernel_1672/1862020553.py:44: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cosine=num/den\n",
      "/var/folders/j4/9fk3st2d30g22vff83pj6cnw0000gn/T/ipykernel_1672/1862020553.py:53: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  dd=dd[['season', 'episodio', 'titolo', 'trama', 'guest_star', 'prima_visione']][df.season==season]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episodio</th>\n",
       "      <th>titolo</th>\n",
       "      <th>trama</th>\n",
       "      <th>guest_star</th>\n",
       "      <th>prima_visione</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>226</td>\n",
       "      <td>Parasole</td>\n",
       "      <td>Luca trova un parasole in allegato al giornale e lo regala a Silvano, ma quando Paolo viene a conoscenza della cosa la prende male.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 aprile 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>Caramelle</td>\n",
       "      <td>Luca e Paolo cercano invano di fare uno scherzo molto \"sporco\" a Silvano.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20 dicembre 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>Gita aziendale</td>\n",
       "      <td>Luca e Paolo sono stati esclusi dalla gita aziendale in montagna, ma Silvano non ha il coraggio di dirglielo.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20 dicembre 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>Il funerale della mamma del Presidente</td>\n",
       "      <td>Tutti i dipendenti partecipano al funerale della madre del Presidente con l'eccezione di Luca e Paolo, che lo disertano con gioia. Quando, però, i due scopriranno da Silvano che i dipendenti che hanno partecipato al funerale avranno la giornata libera, i due fingeranno di essere stati presenti.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15 aprile 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>Il primo giorno di Patti</td>\n",
       "      <td>Con un salto indietro nel tempo, scopriamo l'arrivo in azienda di Patti: assunta come segretaria di Ilaria, Patti viene immediatamente presa di mira da Luca e Paolo, che cercano subito di farle fare brutta figura con il suo nuovo capo, ma con Silvano è subito un colpo di fulmine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20 febbraio 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "      <td>Un piano pauroso</td>\n",
       "      <td>Luca e Paolo spaventano a morte Silvano con una misteriosa VHS[6]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20 gennaio 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>Lo scherzo dell'uovo</td>\n",
       "      <td>Luca e Paolo mostrano a Silvano lo scherzo dell'uovo sodo.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20 gennaio 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>205</td>\n",
       "      <td>Prurito</td>\n",
       "      <td>Silvano parte per le ferie e si vendica di uno scherzo subìto da Luca e Paolo.</td>\n",
       "      <td>['Igor Loddo']</td>\n",
       "      <td>29 marzo 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>Lo scherzone</td>\n",
       "      <td>Silvano fa uno scherzo a Luca e Paolo per vendicarsi.</td>\n",
       "      <td>['Antonio Zavatteri']</td>\n",
       "      <td>20 gennaio 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>155</td>\n",
       "      <td>Pericolo tattoo</td>\n",
       "      <td>Paolo e Luca fanno un tatuaggio a Silvano.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12 marzo 2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k=10\n",
    "query=\"luca paolo geller silvano\"\n",
    "query_ranking(query,k,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea42a0-3efd-4b6f-a7ad-de2d470dbd2a",
   "metadata": {},
   "source": [
    "# Prove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c669fa4-4fa3-4afa-9ad4-0e4e85910f45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k=5\n",
    "query=\"lotteria\"\n",
    "query_ranking_allMatch(query,k)\n",
    "query_ranking(query,k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
